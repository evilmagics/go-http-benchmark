# ğŸš€ Beego: /large-process (Basic)

## ğŸ“‹ Test Configuration
| Parameter | Value |
|-----------|-------|
| ğŸ¯ Target | Beego Framework |
| ğŸŒ URL | http://127.0.0.1:6004/large-process |
| ğŸ“¡ Method | POST |
| ğŸ”— Connections | 100 |
| ğŸ“Š Target Requests | 10,000 |
| â±ï¸ Duration | 30 seconds |
| ğŸ“… Timestamp | 2025-06-30_23-21-08 |

## ğŸƒâ€â™‚ï¸ Performance Overview

| Tool | Total Requests | Duration | Avg Req/sec | Peak Req/sec | Success Rate |
|------|----------------|----------|-------------|--------------|--------------|
| **ğŸ’¥ Bombardier** | 10,000 | ~0.60s | 21,276.58 | 31,760.13 | 100% âœ… |
| **âš¡ Go-Wrk** | 492,072 | 30.21s | 16,289.62 | 16,038.48 | 100% âœ… |
| **ğŸŒ¿ Vegeta** | 245,125 | 30.19s | 8,165.07 | 8,074.56 | 99.43% âš ï¸ |

## â° Latency Analysis

| Metric | ğŸ’¥ Bombardier | âš¡ Go-Wrk | ğŸŒ¿ Vegeta |
|--------|------------|---------|---------|
| **ğŸ“Š Average** | 4.63ms | 6.138ms | 43.573ms |
| **ğŸ“ˆ Standard Deviation** | 11.71ms | 19.417ms | N/A |
| **âš¡ Minimum** | N/A | 0s | 443.5Âµs |
| **ğŸ“Š 50th Percentile** | 0.721ms | 0s | 7.219ms |
| **ğŸ“ˆ 75th Percentile** | 3.65ms | 0s | N/A |
| **ğŸ“Š 90th Percentile** | 10.16ms | N/A | 26.156ms |
| **ğŸ“ˆ 95th Percentile** | 15.89ms | N/A | 65.338ms |
| **ğŸ”º 99th Percentile** | 77.70ms | 0s | 462.552ms |
| **âš ï¸ Maximum** | 181.88ms | 555.583ms | 16.452s |

## ğŸ” HTTP Response Analysis

| Tool | 2xx Responses | Total Errors | Success Rate | Error Details |
|------|---------------|--------------|--------------|---------------|
| **ğŸ’¥ Bombardier** | 10,000 | 0 | 100% âœ… | No errors |
| **âš¡ Go-Wrk** | 492,072 | 0 | 100% âœ… | No errors |
| **ğŸŒ¿ Vegeta** | 243,733 | 1,392 | 99.43% âš ï¸ | Connection refused & timeout errors |

## ğŸ“Š Throughput Analysis

| Tool | Throughput | Total Data | Transfer Rate |
|------|------------|------------|---------------|
| **ğŸ’¥ Bombardier** | 6.51 MB/s | N/A | 6.51 MB/s |
| **âš¡ Go-Wrk** | 2.67 MB/s | 80.72 MB | 2.63 MB/s |
| **ğŸŒ¿ Vegeta** | N/A | 16.09 MB | N/A |

## ğŸ“ˆ Summary

### ğŸ¯ Performance Metrics
- **ğŸ“Š Average Requests/sec**: 15,243.76 req/s
- **ğŸš€ Peak Requests/sec**: 31,760.13 req/s
- **âœ… Overall Success Rate**: 99.81%
- **ğŸ’¨ Average Throughput**: 4.59 MB/s
- **ğŸŒ Average Latency**: 18.11ms

### ğŸ” Key Observations

#### ğŸ—ï¸ POST vs GET Performance Comparison
- **ğŸ“‰ Reduced Throughput**: POST operations show ~50% lower performance vs GET endpoints
- **â±ï¸ Increased Latency**: Average latency increased significantly (18ms vs ~2ms for GET)
- **ğŸ’¾ Processing Overhead**: Complex processing operations impact response times substantially

#### ğŸ”§ Tool-Specific Behavior
- **ğŸ’¥ Bombardier Excellence**: Achieved highest throughput (21K req/s) with consistent sub-5ms latency
- **âš¡ Go-Wrk Stability**: Maintained steady 16K req/s over full 30-second duration with zero errors
- **ğŸŒ¿ Vegeta Challenges**: Struggled with POST operations, showing 0.57% error rate and high tail latency

#### ğŸ“Š Latency Distribution Insights
- **ğŸš€ Fast Path**: 50th percentile shows sub-1ms processing for most requests
- **ğŸ“ˆ Tail Latency**: 99th percentile reveals significant outliers (77-462ms range)
- **âš ï¸ Extreme Cases**: Maximum latency reached 16.4s in Vegeta tests, indicating potential timeouts

#### ğŸ¯ Framework Characteristics
- **ğŸ”„ Resource Processing**: Beego handles complex POST operations efficiently under moderate load
- **ğŸ’ª Concurrency Handling**: Maintains good performance with 100 concurrent connections
- **ğŸ“ˆ Scalability Ceiling**: Performance degradation visible at sustained high loads

#### ğŸ› ï¸ Optimization Opportunities
- **âš¡ POST Processing**: Optimize large data processing workflows
- **ğŸ”§ Connection Tuning**: Address connection pool limits causing Vegeta errors
- **ğŸ“Š Monitoring**: Implement tail latency monitoring for production workloads
- **ğŸš€ Caching**: Consider request/response caching for frequently processed data

#### ğŸ’¡ Production Recommendations
- **ğŸ¯ Load Testing**: Establish baseline performance metrics for POST-heavy workloads
- **âš–ï¸ Capacity Planning**: Plan for 50% throughput reduction compared to GET operations
- **ğŸ” Error Handling**: Implement robust timeout and retry mechanisms for edge cases
- **ğŸ“ˆ Monitoring**: Set up alerts for tail latency spikes (>100ms P99)

---
<div align="center">
ğŸ” Researched with â¤ï¸ by <span><a href="https://github.com/evilmagics">âœ¨ Evilmagics ğŸŒŸ</a></span>
</div>